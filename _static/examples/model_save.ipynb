{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Saving a Model\"\n",
        "execute:\n",
        "  eval: false\n",
        "---"
      ],
      "id": "8cf0f065"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the Data\n",
        "\n",
        "This tutorial illustrates how to correctly store a `neer-match` model. Before getting to the part that illustrates the saving, we have to repeat the steps detailed in **Data Preparation for Training**:\n"
      ],
      "id": "0e136666"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "from neer_match.similarity_map import SimilarityMap\n",
        "from neer_match_utilities.panel import SetupData\n",
        "from neer_match_utilities.prepare import Prepare\n",
        "from neer_match_utilities.training import Training\n",
        "from neer_match_utilities.split import split_test_train\n",
        "from neer_match_utilities.custom_similarities import CustomSimilarities\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# Load files\n",
        "\n",
        "matches = pd.read_csv('matches.csv')\n",
        "left = pd.read_csv('left.csv')\n",
        "right = pd.read_csv('right.csv')\n",
        "\n",
        "# Preparation\n",
        "\n",
        "left, right, matches = SetupData(matches=matches).data_preparation_cs(\n",
        "    df_left=left,\n",
        "    df_right=right,\n",
        "    unique_id='company_id'\n",
        ")\n",
        "\n",
        "# Load custom similarities dedicated to missing values from the utilities package\n",
        "\n",
        "CustomSimilarities()\n",
        "\n",
        "# Define similarity_map\n",
        " \n",
        "similarity_map = {\n",
        "    \"company_name\" : [\n",
        "        \"levenshtein\",\n",
        "        \"jaro_winkler\",\n",
        "        \"prefix\",\n",
        "        \"postfix\",\n",
        "        \"token_sort_ratio\",\n",
        "        \"token_set_ratio\",\n",
        "        \"partial_token_set_ratio\",\n",
        "        \"partial_token_sort_ratio\",\n",
        "    ],\n",
        "    \"city\" : [\n",
        "        \"levenshtein\",\n",
        "        \"jaro_winkler\",\n",
        "        \"notmissing\",\n",
        "    ],\n",
        "    \"industry\" : [\n",
        "        \"levenshtein\",\n",
        "        \"jaro_winkler\",\n",
        "        \"notmissing\",\n",
        "    ],\n",
        "    \"purpose\" : [\n",
        "        \"levenshtein\",\n",
        "        \"jaro_winkler\",\n",
        "        \"token_sort_ratio\",\n",
        "        \"token_set_ratio\",\n",
        "        \"partial_token_set_ratio\",\n",
        "        \"partial_token_sort_ratio\",\n",
        "        \"notmissing\",\n",
        "    ],\n",
        "    \"bs_text\" : [\n",
        "        \"levenshtein\",\n",
        "        \"jaro_winkler\",\n",
        "        \"token_sort_ratio\",\n",
        "        \"token_set_ratio\",\n",
        "        \"partial_token_set_ratio\",\n",
        "        \"partial_token_sort_ratio\",\n",
        "        \"notmissing\",\n",
        "    ],\n",
        "    \"found_year\" : [\n",
        "        \"discrete\",\n",
        "        \"notzero\"\n",
        "    ],\n",
        "    \"found_date_modified\" : [\n",
        "        \"discrete\",\n",
        "        \"notmissing\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "smap = SimilarityMap(similarity_map)\n",
        "\n",
        "prepare = Prepare(\n",
        "    similarity_map=similarity_map, \n",
        "    df_left=left, \n",
        "    df_right=right, \n",
        "    id_left='company_id', \n",
        "    id_right='company_id'\n",
        ")\n",
        "\n",
        "left, right = prepare.format(\n",
        "    fill_numeric_na=False,\n",
        "    to_numeric=['found_year'],\n",
        "    fill_string_na=True, \n",
        "    capitalize=True\n",
        ")\n",
        "\n",
        "# Re-Structuring\n",
        "\n",
        "training = Training(\n",
        "    similarity_map=similarity_map, \n",
        "    df_left=left, \n",
        "    df_right=right, \n",
        "    id_left='company_id', \n",
        "    id_right='company_id'\n",
        ")\n",
        "\n",
        "matches = training.matches_reorder(\n",
        "    matches, \n",
        "    matches_id_left='left', \n",
        "    matches_id_right='right'\n",
        ")\n",
        "\n",
        "# Splitting data\n",
        "\n",
        "left_train, right_train, matches_train, left_validation, right_validation, matches_validation, left_test, right_test, matches_test = split_test_train(\n",
        "    left = left,\n",
        "    right = right,\n",
        "    matches = matches,\n",
        "    test_ratio = .7,\n",
        "    validation_ratio = .0\n",
        ")"
      ],
      "id": "1c5d9a74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Model\n",
        "\n",
        "Once the data is in the correct structure, training the model follows. Note that this example utilizes the custom `combined_loss` function. This loss function is designed to address class imbalance by assigning higher weights to the minority class and focusing the model's learning on hard-to-classify examples, while simultaneously aligning optimization with the F1 score to balance precision and recall. By reducing the loss contribution from well-classified examples, it is particularly effective for imbalanced datasets. Its design is based on ideas presented in [Lin et al. (2017)](https://ieeexplore.ieee.org/document/8237586) as well as [Bénédict et al. (2021)](https://arxiv.org/pdf/2108.10566).\n",
        "\n",
        "In detail, the `combined_loss` is defined as\n",
        "\n",
        "$$\n",
        "\\text{CombinedLoss}(y,\\hat y)\n",
        "= w_{\\mathrm{F1}}\\bigl(1-\\text{SoftF1}(y,\\hat y;\\,\\varepsilon)\\bigr)\n",
        "\\;+\\;\n",
        "(1-w_{\\mathrm{F1}})\\,\\text{FL}(y,\\hat y;\\,\\alpha,\\gamma),\n",
        "$$\n",
        "\n",
        "where \\(y \\in \\{0,1\\}\\) are true labels and \\(\\hat y \\in [0,1]\\) are predicted probabilities.\n",
        "\n",
        "The soft F1 is\n",
        "\n",
        "$$\n",
        "\\text{SoftF1}\n",
        "= \\frac{2\\,TP + \\varepsilon}{2\\,TP + FP + FN + \\varepsilon},\n",
        "$$\n",
        "\n",
        "with \\(TP, FP, FN\\) computed as **soft counts** (sums over probabilities) and \\(\\varepsilon > 0\\) for numerical stability.\n",
        "\n",
        "The binary focal loss is\n",
        "\n",
        "$$\n",
        "\\text{FL}(y,\\hat y;\\alpha,\\gamma)\n",
        "= -\\,\\alpha_t\\,(1-p_t)^\\gamma \\,\\log(p_t),\n",
        "\\qquad\n",
        "p_t =\n",
        "\\begin{cases}\n",
        "\\hat y, & y=1,\\\\\n",
        "1-\\hat y, & y=0,\n",
        "\\end{cases}\n",
        "\\qquad\n",
        "\\alpha_t =\n",
        "\\begin{cases}\n",
        "\\alpha, & y=1,\\\\\n",
        "1-\\alpha, & y=0.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "To balance the *total* weight of positives and negatives in the loss, pick $\\alpha$ such that the summed positive weight equals the summed negative weight:\n",
        "\n",
        "$$\n",
        "\\alpha \\cdot N_{+} \\;=\\; (1-\\alpha)\\cdot N_{-}\n",
        "\\;\\;\\Longrightarrow\\;\\;\n",
        "\\boxed{\\alpha = \\frac{N_{-}}{N_{+} + N_{-}}},\n",
        "$$\n",
        "\n",
        "with\n",
        "\n",
        "$$\n",
        "N_{+} = \\mathrm{len}(\\text{matches}), \\qquad\n",
        "N_{-} = \\mathrm{len}(\\text{left}) \\times \\mathrm{len}(\\text{right}) - \\mathrm{len}(\\text{matches}).\n",
        "$$\n"
      ],
      "id": "fdd7cf85"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "from neer_match.matching_model import DLMatchingModel, NSMatchingModel\n",
        "from neer_match_utilities.training import combined_loss, alpha_balanced\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Initialize the model\n",
        "\n",
        "model = DLMatchingModel(\n",
        "    similarity_map=smap,\n",
        "    initial_feature_width_scales = 10,\n",
        "    feature_depths = 4,\n",
        "    initial_record_width_scale=10,\n",
        "    record_depth = 8,\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "## Calculate the alpha parameter given the dimensions of the training data\n",
        "mismatch_share = 1.0\n",
        "\n",
        "alpha = alpha_balanced(left_train, right_train, matches_train, mismatch_share)  # ≈ N_neg / (N_pos + N_neg)\n",
        "\n",
        "## Use expontantial decay for the learning rate\n",
        "\n",
        "initial_lr = 1e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=initial_lr,\n",
        "    decay_steps=5000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss = combined_loss(\n",
        "        weight_f1=0.5, \n",
        "        epsilon=1e-07, \n",
        "        alpha=alpha, \n",
        "        gamma=0.5\n",
        "    ),\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=lr_schedule, \n",
        "        clipnorm=.5\n",
        "    )\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "\n",
        "model.fit(\n",
        "    left_train, right_train, matches_train,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    mismatch_share=mismatch_share,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "id": "0bba8c2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export the Model\n",
        "\n",
        "Once the model is trained, it can be exported via the `Model` class. The `name` parameter specifies the label of the folder in which the model will be stored.\n"
      ],
      "id": "4acdfa8f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "from neer_match_utilities.model import Model\n",
        "from pathlib import Path\n",
        "\n",
        "Model.save(\n",
        "    model = model,\n",
        "    target_directory = Path(__file__).resolve().parent,\n",
        "    name = 'example_model'\n",
        ")"
      ],
      "id": "983a2813",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Performance Statistics\n",
        "\n",
        "In addition to this, we can evaluate the model on both the training and test datasets, and export the corresponding performance statistics into the folder created when exporting the model.\n"
      ],
      "id": "32cba4ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Evaluate the model\n",
        "\n",
        "performance_train= model.evaluate(\n",
        "    left_train, \n",
        "    right_train, \n",
        "    matches_train,\n",
        "    mismatch_share=1.0\n",
        ")\n",
        "\n",
        "performance_test = model.evaluate(\n",
        "    left_test, \n",
        "    right_test, \n",
        "    matches_test,\n",
        "    mismatch_share=1.0\n",
        ")\n",
        "\n",
        "# Export performance statistics\n",
        "\n",
        "training.performance_statistics_export(\n",
        "    model = model,\n",
        "    model_name = 'example_model',\n",
        "    target_directory = Path(__file__).resolve().parent,\n",
        "    evaluation_train = performance_train,\n",
        "    evaluation_test = performance_test,\n",
        ")"
      ],
      "id": "e07ce5eb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}