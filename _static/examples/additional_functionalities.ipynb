{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Additional Functionalities\"\n",
        "execute:\n",
        "  eval: false\n",
        "---"
      ],
      "id": "850ac957"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Name Commonness\n",
        "\n",
        "Standard string similarity measures treat all values equally — \"Smith\" matching \"Smith\" scores the same as \"Ximénez-Fatio\" matching \"Ximénez-Fatio\". In practice, matching on rare values is far more informative than matching on common ones. The `Commonness` class addresses this by computing frequency-based commonness scores for specified variables and registering a custom `commonness_score` similarity function that rewards rare-and-equal matches.\n",
        "\n",
        "For each variable, the class computes how common each value is in a reference corpus and appends a `<variable>_commonness` column (values in [0, 1]) to both DataFrames. The custom similarity function scores pairs as `(1 - |x - y|) * (1 - mean(x, y))`, so identical rare values score high and identical common values score low.\n",
        "\n",
        "Commonness scores should be computed *after* data harmonization (`Prepare.format()`) but *before* training, so that the `_commonness` columns are available as features.\n",
        "\n",
        "The `df_left_full` and `df_right_full` parameters define the full datasets used for frequency estimation. If the training data is representative of the population, you can pass the training DataFrames themselves (i.e., `df_left_full=left` and `df_right_full=right`). If a larger or more complete dataset is available, passing it will yield more reliable frequency estimates.\n"
      ],
      "id": "80e857b0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from neer_match_utilities.prepare import Commonness\n",
        "\n",
        "c = Commonness(\n",
        "    variable_list=['name', 'surname'],\n",
        "    df_left=left,\n",
        "    df_right=right,\n",
        "\n",
        "    # Reference corpus for frequency estimation\n",
        "    df_left_full=left_full,       # full left dataset (or left if representative)\n",
        "    df_right_full=right_full,     # full right dataset (or right if representative)\n",
        "\n",
        "    commonness_source='both',     # \"left\" | \"right\" | \"both\" — which corpus to use\n",
        "    scoring='minmax',             # \"relative\" | \"minmax\" | \"log\"\n",
        "    fill_value=0.0,               # score for unseen values\n",
        "    preprocess=True,              # normalize strings (strip & lowercase) before counting\n",
        ")\n",
        "\n",
        "left, right = c.calculate()"
      ],
      "id": "4105c035",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After calling `calculate()`, the DataFrames contain new columns (e.g., `name_commonness`, `surname_commonness`) that can be included in the `similarity_map` using the `commonness_score` similarity concept.\n",
        "\n",
        "## Stop Word Removal with spaCy\n",
        "\n",
        "The `Prepare` class supports removing stop words from string variables using a [spaCy](https://spacy.io/) language pipeline. Stop words are common words (e.g., \"the\", \"and\", \"of\") that carry little meaning for entity matching and can reduce similarity scores between otherwise matching records.\n",
        "\n",
        "To enable stop word removal, pass a spaCy pipeline name to `spacy_pipeline`. The pipeline provides a language-specific list of stop words. spaCy models are available in more than 20 languages — see [spacy.io/models](https://spacy.io/models) for the full list. You can also specify `additional_stop_words` to remove domain-specific terms that are frequent but uninformative for matching (e.g., legal forms like \"AG\", \"GmbH\"). Stop words are only removed when `remove_stop_words=True` is passed to `prepare.format()`.\n",
        "\n",
        "Note that if the similarity map includes numeric similarity concepts, the corresponding columns must have a numeric dtype. The `to_numeric` argument in `prepare.format()` ensures this by converting the specified columns, which is useful when numeric data was read as strings (e.g., from CSV files).\n"
      ],
      "id": "3281dfc6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prepare = Prepare(\n",
        "    similarity_map=similarity_map,\n",
        "    df_left=left,\n",
        "    df_right=right,\n",
        "    id_left='company_id',\n",
        "    id_right='company_id',\n",
        "    spacy_pipeline='de_core_news_sm',\n",
        "    additional_stop_words=['AG']\n",
        ")\n",
        "\n",
        "# Get formatted and harmonized datasets\n",
        "\n",
        "left, right = prepare.format(\n",
        "    fill_numeric_na=False,\n",
        "    to_numeric=['found_year'],\n",
        "    fill_string_na=True,\n",
        "    capitalize=True,\n",
        "    lower_case=False,\n",
        "    remove_stop_words=True,\n",
        ")"
      ],
      "id": "3b4ff9f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection\n",
        "\n",
        "The `FeatureSelector` allows you to start with a large similarity map — many feature pairs and many similarity concepts per pair — to maximize potential performance, and then automatically reduce it to the most informative subset. It uses a two-stage procedure:\n",
        "\n",
        "1. **Stage 1 — Correlation filtering** (optional): Groups highly correlated features and keeps only the one most correlated with the target variable. This removes redundant features before regularization.\n",
        "2. **Stage 2 — Elastic net regularization**: Fits a penalized logistic regression (L1/L2 mix) with cross-validation to select features that contribute unique predictive information. Features with zero or near-zero coefficients are dropped.\n",
        "\n",
        "The selector is designed for the extreme class imbalance typical in entity matching, where true matches are rare relative to non-matches.\n"
      ],
      "id": "8e37f824"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from neer_match_utilities.feature_selection import FeatureSelector\n",
        "\n",
        "fs = FeatureSelector(\n",
        "    similarity_map=similarity_map,\n",
        "    training_data=(left_train, right_train, matches_train),\n",
        "\n",
        "    # ID and match columns\n",
        "    id_left_col=\"id_unique\",\n",
        "    id_right_col=\"id_unique\",\n",
        "    matches_id_left=\"left\",\n",
        "    matches_id_right=\"right\",\n",
        "    match_col=\"match\",\n",
        "    matches_are_indices=True,\n",
        "\n",
        "    # Stage 1: Correlation filtering\n",
        "    max_correlation=0.95,       # drop features with pairwise correlation > 0.95\n",
        "\n",
        "    # Stage 2: Elastic net\n",
        "    scoring=\"average_precision\", # metric for CV; recommended for imbalanced data\n",
        "    cv=2,                        # number of cross-validation folds\n",
        "    Cs=20,                       # number of regularization strengths to search\n",
        "    class_weight=\"balanced\",     # adjust for class imbalance\n",
        "    min_coef_threshold=0.01,     # drop features with |coefficient| below this\n",
        "\n",
        "    random_state=42,\n",
        "    n_jobs=4,\n",
        ")\n",
        "\n",
        "fs_result = fs.execute()"
      ],
      "id": "97a1e44e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result object contains the reduced similarity map, which can be used directly in subsequent training:\n"
      ],
      "id": "f0c624c4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Updated similarity map with only selected features\n",
        "similarity_map = fs_result.updated_similarity_map\n",
        "\n",
        "# Inspect feature importance via coefficients\n",
        "print(fs_result.coef_by_feature)\n",
        "\n",
        "# Check selection metadata\n",
        "print(f\"Features: {fs_result.meta['n_features_in']} → {fs_result.meta['n_features_selected']}\")"
      ],
      "id": "5608c772",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handling Many-to-Many Matches\n",
        "\n",
        "### Loading the Data\n",
        "\n",
        "First, we import the necessary libraries and load the datasets.\n"
      ],
      "id": "2e4c7597"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "matches = pd.read_csv('matches.csv')\n",
        "left = pd.read_csv('left.csv')\n",
        "right = pd.read_csv('right.csv')"
      ],
      "id": "c432a316",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspecting the Data\n",
        "\n",
        "The first few rows of each dataset show their structure.\n"
      ],
      "id": "4793662c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "matches.head()"
      ],
      "id": "8ae23e4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "left.head()"
      ],
      "id": "12a07483",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "right.head()"
      ],
      "id": "56c95684",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All three DataFrames have the same number of observations:\n"
      ],
      "id": "c1ee34a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "print(f'Number of observations in matches: {len(matches)}')\n",
        "print(f'Number of observations in left: {len(left)}')\n",
        "print(f'Number of observations in right: {len(right)}')"
      ],
      "id": "badfa8be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simulating a Many-to-Many Relationship\n",
        "\n",
        "To demonstrate how to handle more complex matching scenarios, we simulate a many-to-many (m:m) relationship. Assume that the company with `company_id` *1e87fc75b4* in the *left* DataFrame should match with two entries in the *right* DataFrame: the original match *0008e07878* and an additional match *8bf51ba8a0*.\n"
      ],
      "id": "a010dae7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "# Add an extra match to simulate a many-to-many relationship\n",
        "\n",
        "extra_match = pd.DataFrame({\n",
        "    'company_id_left' : ['1e87fc75b4'],\n",
        "    'company_id_right' : ['8bf51ba8a0']\n",
        "})\n",
        "matches = pd.concat([matches, extra_match], ignore_index=True)"
      ],
      "id": "7c9c395b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, inspect the modified `matches` dataframe for the affected IDs:\n"
      ],
      "id": "c1303ff7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "matches[\n",
        "    matches['company_id_left'].isin(['1e87fc75b4', '810c9c3435']) |\n",
        "    matches['company_id_right'].isin(['0008e07878', '8bf51ba8a0'])\n",
        "]"
      ],
      "id": "34b25828",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the Matching Issue\n",
        "\n",
        "Simply adding a new row to the *matches* DataFrame can be problematic. Consider this simplified example:\n",
        "\n",
        "| Left | Right | Implied Real-World Entity |\n",
        "|------|-------|---------------------------|\n",
        "| A    | C     | Entity 1                  |\n",
        "| B    | D     | Entity 2                  |\n",
        "\n",
        "If further evidence shows that record *A* and record *C* represent the same entity, then all related records (*A*, *B*, *C*, *D*) should be grouped together. This grouping implies that every possible pair among these records should be represented (as shown in the first six rows of the table below). The observations *B* and *C* would consequently appear in both the *Left* and *Right* columns, so the *left* and *right* DataFrames need to be adjusted to include these observations in both. The *matches* DataFrame must be expanded with additional entries (highlighted by the <span style=\"color: orange;\">orange</span> rows):\n",
        "\n",
        "| Left | Right |\n",
        "|------|-------|\n",
        "| A    | B     |\n",
        "| A    | C     |\n",
        "| A    | D     |\n",
        "| B    | C     |\n",
        "| B    | D     |\n",
        "| C    | D     |\n",
        "| <span style=\"color: orange;\">B</span>    | <span style=\"color: orange;\">B</span>     |\n",
        "| <span style=\"color: orange;\">C</span>    | <span style=\"color: orange;\">C</span>     |\n",
        "\n",
        "This example highlights why a naive approach of merely adding an extra match does not fully capture the nature of the linking problem.\n",
        "\n",
        "### Correcting the Relationships\n",
        "\n",
        "To correctly group all records representing the same real-world entity, we use the `data_preparation_cs` method from the `SetupData` class. This method automatically completes the matching pairs and adjusts the `left` and `right` datasets accordingly.\n"
      ],
      "id": "3091925b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "from neer_match_utilities.panel import SetupData\n",
        "\n",
        "left, right, matches = SetupData(matches=matches).data_preparation_cs(\n",
        "    df_left=left,\n",
        "    df_right=right,\n",
        "    unique_id='company_id'\n",
        ")"
      ],
      "id": "e4d2705e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Verifying the Adjustments\n",
        "\n",
        "Finally, we verify that the adjustments correctly reflect the intended relationships by checking the relevant company IDs in the updated datasets.\n"
      ],
      "id": "c6df6494"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "# Verify the updated matches for the specific company_ids\n",
        "\n",
        "artificial_group = ['1e87fc75b4', '810c9c3435', '0008e07878', '8bf51ba8a0']\n",
        "\n",
        "matches_subset = matches[\n",
        "    matches['left'].isin(artificial_group) |\n",
        "    matches['right'].isin(artificial_group)\n",
        "].sort_values(['left', 'right'])\n",
        "\n",
        "matches_subset"
      ],
      "id": "a4c8daec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "# Check the corresponding records in the left dataset\n",
        "\n",
        "left_subset = left[\n",
        "    left['company_id'].isin(artificial_group)\n",
        "][['company_id']]\n",
        "left_subset.head(10)"
      ],
      "id": "c8b3d851",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "# Check the corresponding records in the right dataset\n",
        "\n",
        "right_subset = right[\n",
        "    right['company_id'].isin(artificial_group)\n",
        "][['company_id']]\n",
        "right_subset"
      ],
      "id": "1da8d2e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These steps ensure that the data accurately represents the underlying real-world relationships, even when the matching is more complex than a simple 1:1 mapping. To prevent the simulated change from affecting subsequent steps, we drop the observations associated with these IDs.\n"
      ],
      "id": "b168b41c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "left = left[~left['company_id'].isin(artificial_group)].reset_index(drop=False)\n",
        "right = right[~right['company_id'].isin(artificial_group)].reset_index(drop=False)\n",
        "matches = matches[\n",
        "    (~matches['left'].isin(artificial_group))\n",
        "    &\n",
        "    (~matches['right'].isin(artificial_group))\n",
        "].reset_index(drop=False)"
      ],
      "id": "c1b51754",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}